{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tumblr archiver\n",
    "\n",
    "How to backup the pictures, GIFs, and videos **you** liked\n",
    "\n",
    "\n",
    "\n",
    "## Getting Started\n",
    "This guide is for Windows, Mac, and Linux user. \n",
    "\n",
    "### Step 1: Register as Developer\n",
    "1. Got to your Tumblr **settings** (can be found after clicking on the pencil symbol on the top right)\n",
    "2. On the right side click on **apps**\n",
    "3. At the bottom of the white box you can register for the Tumblr API. Click on it.\n",
    "4. Add an application.\n",
    "5. Fill the form. What you actually fill out does not matter\n",
    "6. Go back to **settings** and then to **apps**\n",
    "7. You see the same white box as in step 3 but with your app now. You will later need the **OAuth Consumer Key** and **OAuth Consumer Secret**\n",
    "\n",
    "### Step 2: Install Python\n",
    "1. The program we are going to run is a **python file** (indicated by the .py). Python is a programming language and you need to install it in order to execute the file.\n",
    "\n",
    "2. Go to the [Python website](https://www.anaconda.com/download/). We are downloading Python **3.7**. This programm should work in the same way on all operating systems\n",
    "\n",
    "\n",
    "### Step 3: Download tumblr_archiver.py\n",
    "\n",
    "1. Download and unzip this file: [tumblr-archiver.zip](https://github.com/aauss/tumblr_archiver/zipball/master)\n",
    "\n",
    "2. Unzip the file somewhere easy to find, e.g. in your Downloads folder. \n",
    "\n",
    "\n",
    "### Step 4. Use the Command Line\n",
    "\n",
    "1. The command line is the bit of the computer which makes you feel like you're a hacker. \n",
    "\n",
    "2. \n",
    "- **Windows**: To find the command line, go to your system search and type in \"Anaconda Prompt\". Click it.\n",
    "- **Mac and Linux**: Open the program Terminal\n",
    "\n",
    "3. Your next step is to navigate the prompt to the file archive.py. I explain the most crucial commands to use the command line. But feel free to look up things elsewhere\n",
    "\n",
    "4. On the left hand side of the screen is part your current path. On Windows it shows `C:\\Users\\yourusername>` or just `C:\\>` , and then there is a blinky cursor. On mac it shows `NameOfYourMac:~ yourusername.`.\n",
    "\n",
    "5. Type `cd Downloads` and then press enter. Your screen now reads `C:\\Users\\Unmutual\\yourusername>` or on Mac `NameOfYourMac:Downlaods yourusername.`. \"cd\" stands for \"change directory\". You have gone one directory down! This is equivalent to just double clicking on the downloads folder. If you go wrong, typing `cd ..` will go up one directory again (`back to C:\\Users\\yourusername>`). \n",
    "- **Windows**: `dir` will give you the content of the folder you are in.\n",
    "- **Mac and Linux**: use `ls` instead\n",
    "6. Once you're done pretending to be a hacker, navigate to the folder the file archive.py is in. So:\n",
    "`cd C:\\Users\\yourusername\\Downloads\\tumblr_archiver` OR `cd yourusername\\Downloads\\tumblr_archiver`\n",
    "7. Execute `pip install -r requirements.txt`. This will install some other Python stuff that is needed.\n",
    "\n",
    "\n",
    "### Step 5. Run!\n",
    "\n",
    "1. Plug in your laptop charger, and make sure you have a stable internet connection, and that the laptop won't auto shutdown, sleep or screensaver. This program will run for a while and it's a faff to restart. \n",
    "\n",
    "2. Where the blinky cursor is, type `python archive.py `. The first bit tells your computer to run Python, the second bit tells Python to run the archiver.\n",
    "\n",
    "3. Your command prompt will start spitting fancy sentences onto the screen. Read it to understand what is currently happening! You can do other stuff while you wait, just leave the black command prompt box open and running.\n",
    "\n",
    "### In Case of an Error\n",
    "Since I wrote this script not long ago there might be still some things I did not think about. Write an issue on [Github](https://github.com/aauss/tumblr_archiver/issues), where you also have the script from. If the error is caused by a weak internet connection or your computer suddenly turns of, restart the script as in step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import pytumblr\n",
    "import yaml\n",
    "import os\n",
    "import requests\n",
    "import urllib.request\n",
    "import re\n",
    "import pickle \n",
    "import time\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_oauth(yaml_path):\n",
    "    '''\n",
    "    Return the consumer and oauth tokens with three-legged OAuth process and\n",
    "    save in a yaml file in the user's home directory.\n",
    "    '''\n",
    "\n",
    "    print('Retrieve consumer key and consumer secret from http://www.tumblr.com/oauth/apps')\n",
    "    consumer_key = input('Paste the consumer key here: ')\n",
    "    consumer_secret = input('Paste the consumer secret here: ')\n",
    "\n",
    "    request_token_url = 'http://www.tumblr.com/oauth/request_token'\n",
    "    authorize_url = 'http://www.tumblr.com/oauth/authorize'\n",
    "    access_token_url = 'http://www.tumblr.com/oauth/access_token'\n",
    "\n",
    "    # STEP 1: Obtain request token\n",
    "    oauth_session = OAuth1Session(consumer_key, client_secret=consumer_secret)\n",
    "    fetch_response = oauth_session.fetch_request_token(request_token_url)\n",
    "    resource_owner_key = fetch_response.get('oauth_token')\n",
    "    resource_owner_secret = fetch_response.get('oauth_token_secret')\n",
    "\n",
    "    # STEP 2: Authorize URL + Rresponse\n",
    "    full_authorize_url = oauth_session.authorization_url(authorize_url)\n",
    "\n",
    "    # Redirect to authentication page\n",
    "    print('\\nPlease go here and authorize:\\n{}'.format(full_authorize_url))\n",
    "    redirect_response = input('Allow then paste the full redirect URL here:\\n')\n",
    "\n",
    "    # Retrieve oauth verifier\n",
    "    oauth_response = oauth_session.parse_authorization_response(redirect_response)\n",
    "\n",
    "    verifier = oauth_response.get('oauth_verifier')\n",
    "\n",
    "    # STEP 3: Request final access token\n",
    "    oauth_session = OAuth1Session(\n",
    "        consumer_key,\n",
    "        client_secret=consumer_secret,\n",
    "        resource_owner_key=resource_owner_key,\n",
    "        resource_owner_secret=resource_owner_secret,\n",
    "        verifier=verifier\n",
    "    )\n",
    "    oauth_tokens = oauth_session.fetch_access_token(access_token_url)\n",
    "\n",
    "    tokens = {\n",
    "        'consumer_key': consumer_key,\n",
    "        'consumer_secret': consumer_secret,\n",
    "        'oauth_token': oauth_tokens.get('oauth_token'),\n",
    "        'oauth_token_secret': oauth_tokens.get('oauth_token_secret')\n",
    "    }\n",
    "\n",
    "    yaml_file = open(yaml_path, 'w+')\n",
    "    yaml.dump(tokens, yaml_file, indent=2)\n",
    "    yaml_file.close()\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token():\n",
    "    # Get token\n",
    "    yaml_path = os.path.expanduser('~') + '/.tumblr'\n",
    "    yaml_file = open(yaml_path, \"r\")\n",
    "    tokens = yaml.safe_load(yaml_file)\n",
    "    yaml_file.close()\n",
    "    # Use token to be able to use the client\n",
    "    client = pytumblr.TumblrRestClient(\n",
    "        tokens['consumer_key'],\n",
    "        tokens['consumer_secret'],\n",
    "        tokens['oauth_token'],\n",
    "        tokens['oauth_token_secret'])\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = get_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the overall amount of likes\n",
    "amount_likes = client.likes()[\"liked_count\"]\n",
    "assert amount_likes != -1, \"You don't seem to have any content to download\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(url, content_type, index, tags):\n",
    "    '''A saver funtion for downloading content based on URL'''\n",
    "    os.mkdir('videos')\n",
    "    os.mkdir('images')\n",
    "    tags = tags[:150]  # Otherwise name gets to long\n",
    "    if content_type == \"video\":\n",
    "        try:\n",
    "            path = os.path.join('videos', str(index) + tags + '.mp4')\n",
    "            urllib.request.urlretrieve(url, path)\n",
    "        except:\n",
    "            with open(\"failed_urls.txt\",\"a\") as file:\n",
    "                file.write(url + ' Index:[' + index + ']' + \"\\n\")\n",
    "    else:\n",
    "        try:\n",
    "            img_data = requests.get(url).content\n",
    "            path = os.path.join('images', str(5613) +tags + '.png')\n",
    "            with open(path, 'wb') as handler:\n",
    "                handler.write(img_data)\n",
    "        except:\n",
    "            with open(\"failed_urls.txt\",\"a\") as file:\n",
    "                file.write(url + ' Index:[' + index +']' + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_first_post(client):\n",
    "    now = int(time.time())\n",
    "    past = time.mktime(datetime.strptime(\"01/02/2007\", \"%d/%m/%Y\").timetuple())\n",
    "    timestamp = now - (now - past)/2\n",
    "    posts = client.likes(before=now,limit=51)['liked_posts']\n",
    "    while len(posts) in [0,51]:\n",
    "        posts = client.likes(before=int(timestamp),limit=51)['liked_posts']\n",
    "        if len(posts) == 0:\n",
    "            past = timestamp\n",
    "            timestamp = now - (now - past)/2\n",
    "        elif len(posts) == 51:\n",
    "            now = timestamp\n",
    "            timestamp = now - (now - past)/2\n",
    "    posts = client.likes(before=int(timestamp),limit=51)['liked_posts']\n",
    "    first_post_timestamp = min([posts[k]['liked_timestamp'] for k in range(len(posts))])\n",
    "    pickle.dump(first_post_timestamp, open(\"first_timestamp.p\", 'wb'))\n",
    "    return first_post_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sim(ts):\n",
    "    now = int(time.time())\n",
    "    if (now - 1000) < ts < now:\n",
    "        return 51\n",
    "    elif ts < (now - 2000):\n",
    "        return 0\n",
    "    else:\n",
    "        return 10\n",
    "def find_first_post():\n",
    "    now = int(time.time())\n",
    "    past = time.mktime(datetime.strptime(\"01/02/2007\", \"%d/%m/%Y\").timetuple())\n",
    "    timestamp = now - (now - past)/2\n",
    "    posts = 51\n",
    "    while posts in [0,51]:\n",
    "        posts = sim(timestamp)\n",
    "        if posts == 0:\n",
    "            past = timestamp\n",
    "            timestamp = now - (now - past)/2\n",
    "        elif posts == 51:\n",
    "            now = timestamp\n",
    "            timestamp = now - (now - past)/2\n",
    "    posts = sim(timestamp)\n",
    "    return posts\n",
    "find_first_post()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-12-07 17:30:42'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.utcfromtimestamp().strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.load(open('checkpoint.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\"caused_error_url\" : [],\n",
    "              \"not_found_contenttype\": [],\n",
    "              \"offsets\" : [1415545092],\n",
    "              \"name_dict\" : {},\n",
    "              \"num_post\" : 0,\n",
    "              \"current_api_call\" : 0 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_calls_for_content():\n",
    "    posts = []\n",
    "    for api_call in tqdm(range(160)):\n",
    "        # Iterate over batches of size 49 to create as little requests as possible\n",
    "        request = client.likes(after=checkpoint[\"offsets\"][-1],limit=51)\n",
    "        new_offset = max([request[\"liked_posts\"][k]['liked_timestamp'] for k in range(len(request[\"liked_posts\"]))])\n",
    "        checkpoint[\"offsets\"].append(new_offset)\n",
    "        posts.extend(request[\"liked_posts\"])\n",
    "    pickle.dump(posts, open('posts.p', 'wb'))\n",
    "    return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE FAILED FIRST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Messy draft\n",
    "empty_posts = 0\n",
    "for index, post in enumerate(tqdm(posts[421:])):\n",
    "    index += 421\n",
    "    if len(post) >=1:\n",
    "        content_type = post['type']\n",
    "        tags = \"_\".join(post['tags'])\n",
    "        index = str(index)\n",
    "        if content_type == \"photo\":\n",
    "            # If only one photo, download, otherwise iterate over them and download\n",
    "            if len(post[\"photos\"]) == 1:\n",
    "                url = post[\"photos\"][0][\"original_size\"]['url']\n",
    "                save(url, content_type, index, tags)\n",
    "            else:\n",
    "                index += \"_{}\"\n",
    "                for j in range(len(post[\"photos\"])):\n",
    "                    url = post[\"photos\"][j][\"original_size\"]['url']\n",
    "                    save(url, content_type, index.format(j), tags)\n",
    "        elif content_type == \"text\":\n",
    "            # Get the body as an HTML style string. Use Regex to extract photo URLs\n",
    "            # If only one photo, download, otherwise iterate over them an download\n",
    "            content = post[\"body\"]\n",
    "            url_s = re.findall(r'src=\"(http[s]:[\\S]*media\\.tumblr\\.com[\\S]*)\"',content)\n",
    "            if len(url_s) == 1:\n",
    "                save(url_s[0],content_type,index, tags)\n",
    "            else:\n",
    "                index += \"_{}\"\n",
    "                for j in range(len(url_s)):\n",
    "                    save(url_s[j],content_type, index.format(j), tags)\n",
    "        elif content_type == \"video\":\n",
    "            # Download the video file\n",
    "            try:\n",
    "                url_s = post[\"video_url\"]\n",
    "                save(url_s, content_type,index, tags)\n",
    "            except KeyError:\n",
    "                pass\n",
    "            \n",
    "    else:\n",
    "        empty_posts += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
