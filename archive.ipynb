{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tumblr archiver\n",
    "\n",
    "How to backup the things **you** liked\n",
    "\n",
    "\n",
    "\n",
    "## Getting Started\n",
    "This guide is for Windows, Mac, and Linux user. \n",
    "\n",
    "### Step 1: Install Python\n",
    "1. The program we are going to run is a **python file**. This means it is a file written in the programming language Python.\n",
    "\n",
    "2. Go to the [Python website](https://www.anaconda.com/download/). We are downloading Python **3.7** \n",
    "\n",
    "\n",
    "### Step 2: Download tumblr_archiver.py\n",
    "\n",
    "1. Download and unzip this file: [tumblr-archiver.zip](https://github.com/aauss/tumblr_archiver/zipball/master)\n",
    "\n",
    "2. Unzip the file somewhere easy to find, say in your Downloads folder. \n",
    "\n",
    "\n",
    "\n",
    "### Step 3. Use the Command Line\n",
    "\n",
    "1. The command line is the bit of the computer which makes you feel like you're in the Matrix. \n",
    "\n",
    "2. To find the command line, go to your system search and type in \"Anaconda Prompt\". Click it.\n",
    "\n",
    "3. Your next step is to navigate the prompt to the file tumblr_backup.py. There are better guides out there than this for using the prompt. I am going to explain, but feel free to google for one with pictures.\n",
    "\n",
    "4. On the left hand side of the screen is part of a Path. For me, it reads `C:\\Users\\yourusername>`, and then there is a blinky cursor. \n",
    "\n",
    "5. Type `cd Downloads` and then press enter. Your screen now reads `C:\\Users\\Unmutual\\yourusername>`. \"cd\" stands for \"change directory\". You have gone one directory down! This is equivalent to just double clicking on the downloads folder. If you go wrong, typing `cd ..` will go up one directory again (`back to C:\\Users\\yourusername>`). If you simply type \"dir\" it will give you a list of all the files in that directory.\n",
    "\n",
    "6. Once you're done pretending to be in the Matrix, navigate to the folder the file archive.py is in. So:\n",
    "`cd C:\\Users\\yourusername\\Downloads\\tumblr_archiver`\n",
    "\n",
    "### Step 4. Run!\n",
    "\n",
    "1. Plug in your laptop charger, and make sure you have a stable internet connection, and that the laptop won't auto shutdown, sleep or screensaver. This program will run for a while and it's a faff to restart.\n",
    "\n",
    "2. Where the blinky cursor is, type `python archive.py `. The first bit tells the Windows to run Python, the second bit tells Python to run the backup script.\n",
    "\n",
    "3. Your command prompt will start spitting letters and phrases onto the screen. Leave it to it! You can do other stuff while you wait, just leave the black command prompt box open and running.\n",
    "\n",
    "### Step 5. How tumblr_backup works\n",
    "\n",
    "Reading the text in the command line will tell you exactly what is happening.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import pytumblr\n",
    "import yaml\n",
    "import os\n",
    "import requests\n",
    "import urllib.request\n",
    "import re\n",
    "import pickle \n",
    "import time\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_oauth(yaml_path):\n",
    "    '''\n",
    "    Return the consumer and oauth tokens with three-legged OAuth process and\n",
    "    save in a yaml file in the user's home directory.\n",
    "    '''\n",
    "\n",
    "    print('Retrieve consumer key and consumer secret from http://www.tumblr.com/oauth/apps')\n",
    "    consumer_key = input('Paste the consumer key here: ')\n",
    "    consumer_secret = input('Paste the consumer secret here: ')\n",
    "\n",
    "    request_token_url = 'http://www.tumblr.com/oauth/request_token'\n",
    "    authorize_url = 'http://www.tumblr.com/oauth/authorize'\n",
    "    access_token_url = 'http://www.tumblr.com/oauth/access_token'\n",
    "\n",
    "    # STEP 1: Obtain request token\n",
    "    oauth_session = OAuth1Session(consumer_key, client_secret=consumer_secret)\n",
    "    fetch_response = oauth_session.fetch_request_token(request_token_url)\n",
    "    resource_owner_key = fetch_response.get('oauth_token')\n",
    "    resource_owner_secret = fetch_response.get('oauth_token_secret')\n",
    "\n",
    "    # STEP 2: Authorize URL + Rresponse\n",
    "    full_authorize_url = oauth_session.authorization_url(authorize_url)\n",
    "\n",
    "    # Redirect to authentication page\n",
    "    print('\\nPlease go here and authorize:\\n{}'.format(full_authorize_url))\n",
    "    redirect_response = input('Allow then paste the full redirect URL here:\\n')\n",
    "\n",
    "    # Retrieve oauth verifier\n",
    "    oauth_response = oauth_session.parse_authorization_response(redirect_response)\n",
    "\n",
    "    verifier = oauth_response.get('oauth_verifier')\n",
    "\n",
    "    # STEP 3: Request final access token\n",
    "    oauth_session = OAuth1Session(\n",
    "        consumer_key,\n",
    "        client_secret=consumer_secret,\n",
    "        resource_owner_key=resource_owner_key,\n",
    "        resource_owner_secret=resource_owner_secret,\n",
    "        verifier=verifier\n",
    "    )\n",
    "    oauth_tokens = oauth_session.fetch_access_token(access_token_url)\n",
    "\n",
    "    tokens = {\n",
    "        'consumer_key': consumer_key,\n",
    "        'consumer_secret': consumer_secret,\n",
    "        'oauth_token': oauth_tokens.get('oauth_token'),\n",
    "        'oauth_token_secret': oauth_tokens.get('oauth_token_secret')\n",
    "    }\n",
    "\n",
    "    yaml_file = open(yaml_path, 'w+')\n",
    "    yaml.dump(tokens, yaml_file, indent=2)\n",
    "    yaml_file.close()\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token():\n",
    "    # Get token\n",
    "    yaml_path = os.path.expanduser('~') + '/.tumblr'\n",
    "    yaml_file = open(yaml_path, \"r\")\n",
    "    tokens = yaml.safe_load(yaml_file)\n",
    "    yaml_file.close()\n",
    "    # Use token to be able to use the client\n",
    "    client = pytumblr.TumblrRestClient(\n",
    "        tokens['consumer_key'],\n",
    "        tokens['consumer_secret'],\n",
    "        tokens['oauth_token'],\n",
    "        tokens['oauth_token_secret'])\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the overall amount of likes\n",
    "amount_likes = client.likes()[\"liked_count\"]\n",
    "assert amount_likes != -1, \"You don't seem to have any content to download\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(url, content_type, index, tags):\n",
    "    '''A saver funtion for downloading content based on URL'''\n",
    "    os.mkdir('videos')\n",
    "    os.mkdir('images')\n",
    "    tags = tags[:150]  # Otherwise name gets to long\n",
    "    if content_type == \"video\":\n",
    "        try:\n",
    "            path = os.path.join('videos', str(index) + tags + '.mp4')\n",
    "            urllib.request.urlretrieve(url, path)\n",
    "        except:\n",
    "            with open(\"failed_urls.txt\",\"a\") as file:\n",
    "                file.write(url + ' Index:[' + index + ']' + \"\\n\")\n",
    "    else:\n",
    "        try:\n",
    "            img_data = requests.get(url).content\n",
    "            path = os.path.join('images', str(5613) +tags + '.png')\n",
    "            with open(path, 'wb') as handler:\n",
    "                handler.write(img_data)\n",
    "        except:\n",
    "            with open(\"failed_urls.txt\",\"a\") as file:\n",
    "                file.write(url + ' Index:[' + index +']' + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_first_post():\n",
    "    now = int(time.time())\n",
    "    past = time.mktime(datetime.strptime(\"01/02/2007\", \"%d/%m/%Y\").timetuple())\n",
    "    timestamp = now - (now - past)/2\n",
    "    posts = client.likes(before=now,limit=51)['liked_posts']\n",
    "    while len(posts) in [0,51]:\n",
    "        posts = client.likes(before=int(timestamp),limit=51)['liked_posts']\n",
    "        if len(posts) == 0:\n",
    "            past = timestamp\n",
    "            timestamp = now - (now - timestamp)/2\n",
    "        elif len(posts) == 51:\n",
    "            now = timestamp\n",
    "            timestamp = timestamp - (timestamp-start_of_tumblr)/2\n",
    "    posts = client.likes(before=int(timestamp),limit=51)['liked_posts']\n",
    "    return min([posts[k]['liked_timestamp'] for k in range(len(posts))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1415545092"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_first_post()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\"caused_error_url\" : [],\n",
    "              \"not_found_contenttype\": [],\n",
    "              \"offsets\" : [1415545092],\n",
    "              \"name_dict\" : {},\n",
    "              \"num_post\" : 0,\n",
    "              \"current_api_call\" : 0 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_calls_for_content():\n",
    "    posts = []\n",
    "    for api_call in tqdm(range(160)):\n",
    "        # Iterate over batches of size 49 to create as little requests as possible\n",
    "        request = client.likes(after=checkpoint[\"offsets\"][-1],limit=51)\n",
    "        new_offset = max([request[\"liked_posts\"][k]['liked_timestamp'] for k in range(len(request[\"liked_posts\"]))])\n",
    "        checkpoint[\"offsets\"].append(new_offset)\n",
    "        posts.extend(request[\"liked_posts\"])\n",
    "    pickle.dump(posts, open('posts.p', 'wb'))\n",
    "    return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE FAILED FIRST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "empty_posts = 0\n",
    "for index, post in enumerate(tqdm(posts[421:])):\n",
    "    index += 421\n",
    "    if len(post) >=1:\n",
    "        content_type = post['type']\n",
    "        tags = \"_\".join(post['tags'])\n",
    "        index = str(index)\n",
    "        if content_type == \"photo\":\n",
    "            # If only one photo, download, otherwise iterate over them and download\n",
    "            if len(post[\"photos\"]) == 1:\n",
    "                url = post[\"photos\"][0][\"original_size\"]['url']\n",
    "                save(url, content_type, index, tags)\n",
    "            else:\n",
    "                index += \"_{}\"\n",
    "                for j in range(len(post[\"photos\"])):\n",
    "                    url = post[\"photos\"][j][\"original_size\"]['url']\n",
    "                    save(url, content_type, index.format(j), tags)\n",
    "        elif content_type == \"text\":\n",
    "            # Get the body as an HTML style string. Use Regex to extract photo URLs\n",
    "            # If only one photo, download, otherwise iterate over them an download\n",
    "            content = post[\"body\"]\n",
    "            url_s = re.findall(r'src=\"(http[s]:[\\S]*media\\.tumblr\\.com[\\S]*)\"',content)\n",
    "            if len(url_s) == 1:\n",
    "                save(url_s[0],content_type,index, tags)\n",
    "            else:\n",
    "                index += \"_{}\"\n",
    "                for j in range(len(url_s)):\n",
    "                    save(url_s[j],content_type, index.format(j), tags)\n",
    "        elif content_type == \"video\":\n",
    "            # Download the video file\n",
    "            try:\n",
    "                url_s = post[\"video_url\"]\n",
    "                save(url_s, content_type,index, tags)\n",
    "            except KeyError:\n",
    "                pass\n",
    "            \n",
    "    else:\n",
    "        empty_posts += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
